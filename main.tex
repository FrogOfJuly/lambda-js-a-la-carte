%%
%% This is file `sample-manuscript.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,manuscript')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-manuscript.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[sigplan,nonacm]{acmart}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2025}
\acmYear{2026}
\acmDOI{XXXXXXX.XXXXXXX}
%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[Conference acronym 'XX]{Make sure to enter the correct
  conference title from your rights confirmation email}{June 03--05,
  2018}{Woodstock, NY}
%%
%%  Uncomment \acmBooktitle if the title of the proceedings is different
%%  from ``Proceedings of ...''!
%%
%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%  June 03--05, 2018, Woodstock, NY}
\acmISBN{978-1-4503-XXXX-X/2018/06}
%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
% \citestyle{acmauthoryear}

\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\newcommand\code[1]{{\tt\small #1}}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{ltblue}{rgb}{0,0.4,0.4}
\definecolor{dkviolet}{rgb}{0.3,0,0.5}
\definecolor{dkblue}{rgb}{0.3,0,0.5}

\lstdefinestyle{mystyle}{
    % backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

% lstlisting coq style (inspired from a file of Assia Mahboubi)
\lstdefinelanguage{Coq}{ 
    % Anything betweeen $ becomes LaTeX math mode
    mathescape=true,
    % Comments may or not include Latex commands
    texcl=false, 
    % Vernacular commands
    morekeywords=[1]{Section, Module, End, Require, Import, Export,
        Variable, Variables, Parameter, Parameters, Axiom, Hypothesis,
        Hypotheses, Notation, Local, Tactic, Reserved, Scope, Open, Close,
        Bind, Delimit, Definition, Let, Ltac, Fixpoint, CoFixpoint, Add,
        Morphism, Relation, Implicit, Arguments, Unset, Contextual,
        Strict, Prenex, Implicits, Inductive, CoInductive, Record,
        Structure, Canonical, Coercion, Context, Class, Global, Instance,
        Program, Infix, Theorem, Lemma, Corollary, Proposition, Fact,
        Remark, Example, Proof, Goal, Save, Qed, Defined, Hint, Resolve,
        Rewrite, View, Search, Show, Print, Printing, All, Eval, Check,
        Projections, inside, outside, Def},
    % Gallina
    morekeywords=[2]{forall, exists, exists2, fun, fix, cofix, struct,
        match, with, end, as, in, return, let, if, is, then, else, for, of,
        nosimpl, when},
    % Sorts
    morekeywords=[3]{Type, Prop, Set, true, false, option},
    % Various tactics, some are std Coq subsumed by ssr, for the manual purpose
    morekeywords=[4]{pose, set, move, case, elim, apply, clear, hnf,
        intro, intros, generalize, rename, pattern, after, destruct,
        induction, using, refine, inversion, injection, rewrite, congr,
        unlock, compute, ring, field, fourier, replace, fold, unfold,
        change, cutrewrite, simpl, have, suff, wlog, suffices, without,
        loss, nat_norm, assert, cut, trivial, revert, bool_congr, nat_congr,
        symmetry, transitivity, auto, split, left, right, autorewrite},
    % Terminators
    morekeywords=[5]{by, done, exact, reflexivity, tauto, romega, omega,
        assumption, solve, contradiction, discriminate},
    % Control
    morekeywords=[6]{do, last, first, try, idtac, repeat},
    % Comments delimiters, we do turn this off for the manual
    morecomment=[s]{(*}{*)},
    % Spaces are not displayed as a special character
    showstringspaces=false,
    % String delimiters
    morestring=[b]",
    morestring=[d]’,
    % Size of tabulations
    tabsize=3,
    % Enables ASCII chars 128 to 255
    extendedchars=false,
    % Case sensitivity
    sensitive=true,
    % Automatic breaking of long lines
    breaklines=false,
    % Default style fors listings
    basicstyle=\small,
    % Position of captions is bottom
    captionpos=b,
    % flexible columns
    columns=[l]flexible,
    % Style for (listings') identifiers
    identifierstyle={\ttfamily\color{black}},
    % Style for declaration keywords
    keywordstyle=[1]{\ttfamily\color{dkviolet}},
    % Style for gallina keywords
    keywordstyle=[2]{\ttfamily\color{blue}},
    % Style for sorts keywords
    keywordstyle=[3]{\ttfamily\color{ltblue}},
    % Style for tactics keywords
    keywordstyle=[4]{\ttfamily\color{dkviolet}},
    % Style for terminators keywords
    keywordstyle=[5]{\ttfamily\color{dkred}},
    %Style for iterators
    %keywordstyle=[6]{\ttfamily\color{dkpink}},
    % Style for strings
    stringstyle=\ttfamily,
    % Style for comments
    commentstyle={\ttfamily\color{dkgreen}},
    %moredelim=**[is][\ttfamily\color{red}]{/&}{&/},
    literate=
    {\\forall}{{\color{dkgreen}{$\forall\;$}}}1
    {\\exists}{{$\exists\;$}}1
    {<-}{{$\leftarrow\;$}}1
    {=>}{{$\Rightarrow\;$}}1
    {==}{{\code{==}\;}}1
    {==>}{{\code{==>}\;}}1
    %    {:>}{{\code{:>}\;}}1
    {->}{{$\rightarrow\;$}}1
    {<->}{{$\leftrightarrow\;$}}1
    {<==}{{$\leq\;$}}1
    {\#}{{$^\star$}}1 
    {\\o}{{$\circ\;$}}1 
    {\@}{{$\cdot$}}1 
    {\/\\}{{$\wedge\;$}}1
    {\\\/}{{$\vee\;$}}1
    {++}{{\code{++}}}1
    {~}{{$\sim$}}1
    {\@\@}{{$@$}}1
    {\\mapsto}{{$\mapsto\;$}}1
    {\\hline}{{\rule{\linewidth}{0.5pt}}}1
    %
}[keywords,comments,strings]

\lstset{style=mystyle}

\usepackage{todonotes}
\setlength {\marginparwidth }{2cm}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{$\lambda_{\texttt{JS}}$ à la Carte}
%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.

\author{Kirill Golubev}
\email{kirill.golubev@utu.fi}
\orcid{0009-0002-2709-5241}
\affiliation{%
  \institution{University of Turku}
  \city{Turku}
  \country{Finland}
}
% \authornote{
%   Supervisor: Jaakko Järvi, jaakko.jarvi@utu.fi, University of Turku, Turku, Finland, orcid: 0000-0002-3418-7366\\
%   Supervisor: Mikhail Barash, mikhail.barash@uib.no, University of Bergen, Bergen, Norway, orcid: 0000-0002-7067-2588
% }


%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Golubev}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
 <concept>
<concept_id>10011007.10010940.10010992.10010998.10010999</concept_id>
<concept_desc>Software and its engineering~Software verification</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~Software verification}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Language mechanization, modular proofs, JavaScript, reactivity.}

% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

\maketitle

\section{Introduction}

\todo[inline]{Half a page for overview and explaining motivation}

In particular,
we are interested in \emph{reactivity} in JavaScript,
which is highly popularized in various developer frameworks
such as React~\cite{React}, Solid~\cite{Solid}, and others.

\section{Background, à la Carte}
% Inlined Functor Fixed Points

%- any inductive type: functor + fixpoint of that functor
%- functor is modular, fixpoint is not modular
%- not functor: any type -> bottom type
%- fixpoint of not will give bottom, that's why coq agda etc. don't allow to make a fixpoint operator as in the datatypes a la carte

%- everyone who is doing a la carte, are trying to avoid this pitfall
%- coq a la carte: their way around is straightforward: we will inline it every time we need to go around
%- by inlining they mean: see fig 1
%- open recursion proofs, closing recursion; see fig 1
%- boilerplate: coq-elpi instead of metarocq: because of ...



\emph{Datatypes à la Carte}~\cite{swierstra2008data}
popularizes the idea of
\emph{extensible} inductive datatypes. 
One of the efforts to bring this idea to proof assistants
was done by \emph{Coq à la Carte}~\cite{forster2020coq},
which enables modularity in proofs.
However,
directly adopting the implementation~\cite{forster2020coq} in practice
is prohibitively difficult
due to its dependency on an outdated version of Metarocq~\cite{sozeau2020metacoq}.

It is possible to represent an inductive type as a fixed point of a functor,
but attempting such a decomposition na\"ively leads to inconsistency\footnote{\texttt{Fix (forall A. A -> False)} allows to obtain proof of \texttt{False}.}. 
Therefore, it is not possible to use explicit fixed point operations for inductive type decomposition in theorem provers.
As shown in the Coq à la Carte approach,
this issue can be circumvented by \emph{inlining} fixed point operations.  
Resulting functors will then allow open-recursion-style per-functor proofs,
which will not rely on a particular structure of the decomposed type.
Once the desired proofs are complete,
the type can be assembled from the desired feature functors as a fixed point of their coproduct,
and proofs can be assembled from
per-functor proofs,
by ``closing'' recursion over them.

\begin{figure}
\begin{lstlisting}[language=Coq]
(* Exp.v *)
Inductive Exp := 
(* Exp type can be seen as inlined fixed point 
   of coproduct of feature functors exp_ite and exp_lam *)
  | inj_ite : exp_ite Exp -> Exp
  | inj_lam : exp_lam Exp -> Exp.
Fixpoint thrm : forall (e : Exp) -> ...
intros. destruct e.
(* close recursion *)
  - apply (thrm_ite Exp thrm ...).
  - apply (thrm_lam Exp thrm ...).
Defined.
(* ITE.v *)
Section exp_ite.
Exp : Type.
Inductive exp_ite := 
  | ite : Exp -> Exp -> Exp
  | boolt_lit : bool -> Exp.
(* assume overarching property *)
Variable thrm : forall (e : Exp) -> ... .
(* Prove corresponding per-functor property *)
Definition thrm_ite : forall (e : exp_lam) -> ... .
End exp_ite.
(* Lambda.v: ommited, similar to ITE.v *)
\end{lstlisting}
  \caption{Minimal example of language extension with ITE constructions.}
  \label{fig:alacart_example}
\end{figure}

These ideas are outlined in Figure~\ref{fig:alacart_example}.
%The apporach is illustrated with an example at Fig \ref{fig:alacart_example} 
%that roughtly outlines extension of untyped lambda calculus with with booleans 
%and if-then-else constructions. 
%However, there is much more to it that is possible to cover here.
As can be seen in the code example,
there is a considerable amount of boilerplate,
and it can be automatically generated.
Here we mention Coq-Elpi~\cite{tassi2025elpi}, which is a rule-based metalanguage for Rocq~\cite{the_coq_development_team_2024_14542673};
it gives a programmer an ability to generate tactics,
inductive types and manipulate syntax with binders.

\section{Targets for Mechanization}

In our work,
we investigate an extensible mechanization of the JavaScript semantics\footnote{We note that mechanizing the entirety of the JavaScript semantics
and developing a generic modular framework are non-goals.}
by \emph{specializing} the à la carte approach described above.
This specialization will be focused on developing meta-tools that would target an impure imperative language without concurrency (in our case, JavaScript),
rather then developing a generic framework suitable for a wide range of target languages.

%where an extensible encoding of desired types preserves their first-class citizenship in the host langauage.

%The goal of this work is to investigate how far one can go while developing extendable mechanization of JavaScript by specializing shallow a-la-carte approach. 
%It is important to facilitate that we neither aiming to formalize the whole existing JavaScript semantics nor to develop a generic modular framework.

Recently, a significant progress~\cite{ebresafe2025certified} was made on applying modular techniques
to mechanize the semantics of major programming languages (cf.~CompCert~\cite{leroy2016compcert} and CakeML\cite{kumar2014cakeml}),
but none of the existing modular approaches targets the JavaScript semantics.
We observe that extending existing JavaScript mechanizations
(cf., e.g.,~\cite{guha2010essence,bodin2014trusted}, which are based on various editions of the exhaustive natural language specification ECMA-262~\cite{ECMA})
with support for new features
is impossible without manually rewriting a significant portion of an existing codebase.

Being one of the most-used languages, JavaScript provides a fertile ground for evaluating approaches for modular reasoning:
its lack of a type system streamlines the encoding and makes it easier to \emph{gradually} prove language properties,
while keeping the mechanization open to extension.


%There are several\cite{guha2010essence}\cite{bodin2014trusted} developments that attempt to formalize and reason about JavaScript, however non of them is easy to extend with new features.
%There was a significant progress recently in applying modular techniques to existing programming languages(e.g. CompCert and CakeML\cite{ebresafe2025certified}), however none of targeted JavaScript.

% Being one of the most used languages, JavaScript provides a fertile ground for evaluating existing approaches for modular reasoning. 
% Lack of type system streamlines the encoding and makes it easier to gradually prove language properties, while keeping the formalization open to extension.
% ECMA\cite{ECMA}, an extensive specification in natural language, is an established source of truth for the language semantics in natural language.


With modularity, proofs about the core language
will be reusable to mechanize the most recent additions to the language
(i.e., the upcoming features -- even before they become part of the ECMA-262 specification).
It will also be possible to reuse proofs for further properties
of the language's dialects (e.g., TypeScript),
as well as various JavaScript frameworks (e.g., React, Solid, Angular, Vue, etc).

We are particularly interested in mechanizing
mutability, exceptions, asynchrony and reactivity of JavaScript---%
in light of the \emph{Signals} proposal~\cite{signals-proposal-t39},
which is currently being considered by the JavaScript committee.

We plan to follow the $\lambda_{\texttt{JS}}$ formalization~\cite{guha2010essence},
and then gradually extend it with the relevant features,
while maintaining the following safety theorems:

\begin{lstlisting}[numbers=none, language=Coq]
Theorem progress : forall c e, lc e -> 
         isValue e \/ 
         isError e \/ 
         (exists c' e', step c e c' e').

Theorem preservation : forall c e c' e', lc e
                                      -> step c e c' e'
                                      -> lc e'.
\end{lstlisting}

%Modularity will enable us to reuse proofs about the core language for dialects and upcoming feathres would be a nice showcase of modularity. For example, it is beneficial to have a formal guarantee that reactivity as described in signals proposal\footnote{https://github.com/tc39/proposal-signals} is sound and compatible with existing reactivity implementations in React, Solid and etc.




%With the goal stated above in mind the following features of JavaScript are of the most interest: mutability, exceptions, reactivity and asynchrony. 
%Moreover, JavaScript has several frameworks\cite{React} and dialects(e.g. TypeScript) that enable different styles of programming. 

%The t39\cite{t39} proposal process is transparent and well documented thus permitting mechanization of ongoing specification of nightly features before they are adopted into core language.
%Ability to reuse proofs about core language for dialects and upcoming feathres would be a nice showcase of modularity. For example, it is beneficial to have a formal guarantee that reactivity as described in signals proposal\footnote{https://github.com/tc39/proposal-signals} is sound and compatible with existing reactivity implementations in React, Solid and etc.

%We plan to, at first, follow $\lambda_{\texttt{JS}}$\cite{guha2010essence} formalization and then gradually extend it with features described in ECMA, while preserving the following theorems.

%\begin{lstlisting}[numbers=none, language=Coq]
%Theorem progress : forall c e, lc e -> 
%         isValue e \/ 
%         isError e \/ 
%         (exists c' e', step c e c' e').
%
%Theorem preservation : forall c e c' e', lc e
%                                      -> step c e c' e'
%                                      -> lc e'.
%\end{lstlisting}

Our ongoing Rocq mechanization is available at \url{https://github.com/FrogOfJuly/js-a-la-Carte}. 

Currently, out implementation includes call-by-value untyped lambda calculus core, **-style mutability, if-then-else constructions and simple error handling. 

\todo[inline]{Expand with functor description and interaction functors}

\section{Related work}

There are other solutions to increase modularity of proofs. 

\medskip

\textbf{Extensible metatheory mechanization via family polymorphism. } FPOP\cite{jin2023extensible} and Rocqet\cite{ebresafe2025certified} are a Rocq language extensions which compile modular inductive types into Rocq modules allowing extension with the help of 
OO-inspired family polymorphism with late bindings. 

Despite its success in formalizing CompCert and CakeML its modular type representation as modules is virtually incompatible with the rest of Rocq which increases learning curve and locks development to this particular dialect. 
\todo[inline]{Am I misinterpreting all of this and it's OK and actually the best solution?}

\medskip
\textbf{Program Logics à la Carte}\cite{vistrup2025program} achieves modularity by encoding effect-emitting(e.g. non-termination, exception, concurrency, etc.) components of the language as fragments of program logic. 
Language semantics is expressed as interaction trees\cite{xia2019interaction}: coinductively defined datatype for representing effectful computations. 
Development provides several program logics fragment which correspond to commonly encountered pieces in different programming languages. 

From the practical point of view however, this approach introduces considerable indirection to encoding and proofs, especially if it is required to define new program logic fragments.

\todo[inline]{Does it?}


\medskip
\textbf{Intrinsically-typed definitional interpreters {\`a} la carte}\cite{van2022intrinsically} leverages finatary containers\cite{altenkirch2015indexed} and algebras over them to introduce "intrinsically-typed language fragments".
Those bring together common syntax and semantics of chosen language features, while allowing composition. 

While very satisfying on it's own, this approach also suffers from indirectness of modular type encoding. Learning curve for container machinery is quite steep and thus makes it hard to adopt for proofs about larger languages.



\todo[inline]{Should be worded better.}

\medskip

% \todo[inline]{It's interesting to look into the possibility of gradually encoding calculus of inductive constructions in a modular fashion.}

\section{Discussion}

Proof modularity comes with the cost of departing from the usual way of reasoning about inductive types. 
Even if in case of Coq à la Carte the departure is not quite dramatic, it still requires to rethink how one approaches proofs.

The ideal solution would be to have a correspondence between proofs for modular representation and equivalent inductive types. 
There is an existing work\cite{cohen2024trocq} that could enable such transfer of proofs. 

\todo[inline]{Talk about how they achieve that and is it possible to leverage that for functor representation of chosen datatype.}

% \todo[inline]{Is it possible to use containers as a meta language, while presreving ability to do actual reasoning with inductive types in Rocq?}


\bibliographystyle{ACM-Reference-Format}
\bibliography{lib}

\appendix


\end{document}
