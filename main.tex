%%
%% This is file `sample-manuscript.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,manuscript')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-manuscript.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[sigplan,nonacm]{acmart}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2025}
\acmYear{2026}
\acmDOI{XXXXXXX.XXXXXXX}
%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[Conference acronym 'XX]{Make sure to enter the correct
  conference title from your rights confirmation email}{June 03--05,
  2018}{Woodstock, NY}
%%
%%  Uncomment \acmBooktitle if the title of the proceedings is different
%%  from ``Proceedings of ...''!
%%
%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%  June 03--05, 2018, Woodstock, NY}
\acmISBN{978-1-4503-XXXX-X/2018/06}
%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
% \citestyle{acmauthoryear}

\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\newcommand\code[1]{{\tt\small #1}}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{ltblue}{rgb}{0,0.4,0.4}
\definecolor{dkviolet}{rgb}{0.3,0,0.5}
\definecolor{dkblue}{rgb}{0.3,0,0.5}

\lstdefinestyle{mystyle}{
    % backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

% lstlisting coq style (inspired from a file of Assia Mahboubi)
\lstdefinelanguage{Coq}{ 
    % Anything betweeen $ becomes LaTeX math mode
    mathescape=true,
    % Comments may or not include Latex commands
    texcl=false, 
    % Vernacular commands
    morekeywords=[1]{Section, Module, End, Require, Import, Export,
        Variable, Variables, Parameter, Parameters, Axiom, Hypothesis,
        Hypotheses, Notation, Local, Tactic, Reserved, Scope, Open, Close,
        Bind, Delimit, Definition, Let, Ltac, Fixpoint, CoFixpoint, Add,
        Morphism, Relation, Implicit, Arguments, Unset, Contextual,
        Strict, Prenex, Implicits, Inductive, CoInductive, Record,
        Structure, Canonical, Coercion, Context, Class, Global, Instance,
        Program, Infix, Theorem, Lemma, Corollary, Proposition, Fact,
        Remark, Example, Proof, Goal, Save, Qed, Defined, Hint, Resolve,
        Rewrite, View, Search, Show, Print, Printing, All, Eval, Check,
        Projections, inside, outside, Def},
    % Gallina
    morekeywords=[2]{forall, exists, exists2, fun, fix, cofix, struct,
        match, with, end, as, in, return, let, if, is, then, else, for, of,
        nosimpl, when},
    % Sorts
    morekeywords=[3]{Type, Prop, Set, true, false, option},
    % Various tactics, some are std Coq subsumed by ssr, for the manual purpose
    morekeywords=[4]{pose, set, move, case, elim, apply, clear, hnf,
        intro, intros, generalize, rename, pattern, after, destruct,
        induction, using, refine, inversion, injection, rewrite, congr,
        unlock, compute, ring, field, fourier, replace, fold, unfold,
        change, cutrewrite, simpl, have, suff, wlog, suffices, without,
        loss, nat_norm, assert, cut, trivial, revert, bool_congr, nat_congr,
        symmetry, transitivity, auto, split, left, right, autorewrite},
    % Terminators
    morekeywords=[5]{by, done, exact, reflexivity, tauto, romega, omega,
        assumption, solve, contradiction, discriminate},
    % Control
    morekeywords=[6]{do, last, first, try, idtac, repeat},
    % Comments delimiters, we do turn this off for the manual
    morecomment=[s]{(*}{*)},
    % Spaces are not displayed as a special character
    showstringspaces=false,
    % String delimiters
    morestring=[b]",
    morestring=[d]’,
    % Size of tabulations
    tabsize=3,
    % Enables ASCII chars 128 to 255
    extendedchars=false,
    % Case sensitivity
    sensitive=true,
    % Automatic breaking of long lines
    breaklines=false,
    % Default style fors listings
    basicstyle=\small,
    % Position of captions is bottom
    captionpos=b,
    % flexible columns
    columns=[l]flexible,
    % Style for (listings') identifiers
    identifierstyle={\ttfamily\color{black}},
    % Style for declaration keywords
    keywordstyle=[1]{\ttfamily\color{dkviolet}},
    % Style for gallina keywords
    keywordstyle=[2]{\ttfamily\color{blue}},
    % Style for sorts keywords
    keywordstyle=[3]{\ttfamily\color{ltblue}},
    % Style for tactics keywords
    keywordstyle=[4]{\ttfamily\color{dkviolet}},
    % Style for terminators keywords
    keywordstyle=[5]{\ttfamily\color{dkred}},
    %Style for iterators
    %keywordstyle=[6]{\ttfamily\color{dkpink}},
    % Style for strings
    stringstyle=\ttfamily,
    % Style for comments
    commentstyle={\ttfamily\color{dkgreen}},
    %moredelim=**[is][\ttfamily\color{red}]{/&}{&/},
    literate=
    {\\forall}{{\color{dkgreen}{$\forall\;$}}}1
    {\\exists}{{$\exists\;$}}1
    {<-}{{$\leftarrow\;$}}1
    {=>}{{$\Rightarrow\;$}}1
    {==}{{\code{==}\;}}1
    {==>}{{\code{==>}\;}}1
    %    {:>}{{\code{:>}\;}}1
    {->}{{$\rightarrow\;$}}1
    {<->}{{$\leftrightarrow\;$}}1
    {<==}{{$\leq\;$}}1
    {\#}{{$^\star$}}1 
    {\\o}{{$\circ\;$}}1 
    {\@}{{$\cdot$}}1 
    {\/\\}{{$\wedge\;$}}1
    {\\\/}{{$\vee\;$}}1
    {++}{{\code{++}}}1
    {~}{{$\sim$}}1
    {\@\@}{{$@$}}1
    {\\mapsto}{{$\mapsto\;$}}1
    {\\hline}{{\rule{\linewidth}{0.5pt}}}1
    %
}[keywords,comments,strings]

\lstset{style=mystyle}

\usepackage{todonotes}
\setlength {\marginparwidth }{2cm}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{$\lambda_{\texttt{JS}}$ à la Carte}
%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.

\author{Kirill Golubev}
\email{kirill.golubev@utu.fi}
\orcid{0009-0002-2709-5241}
\affiliation{%
  \institution{University of Turku}
  \city{Turku}
  \country{Finland}
}
% \authornote{
%   Supervisor: Jaakko Järvi, jaakko.jarvi@utu.fi, University of Turku, Turku, Finland, orcid: 0000-0002-3418-7366\\
%   Supervisor: Mikhail Barash, mikhail.barash@uib.no, University of Bergen, Bergen, Norway, orcid: 0000-0002-7067-2588
% }


%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Golubev}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
 <concept>
<concept_id>10011007.10010940.10010992.10010998.10010999</concept_id>
<concept_desc>Software and its engineering~Software verification</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~Software verification}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{JavaScript, formal methods, verification}

% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

\maketitle

\section{Introduction}

\todo[inline]{Half a page for overview and explaining motivation}

\section{Inlined functor fixpoints }

We follow closely ideas from Data types à la Carte\cite{swierstra2008data} and  Coq à la Carte\cite{forster2020coq} to enable modularity. 
Sadly, direct use of the meta-programming tools developed in the latter is prohibitively difficult due to outdated Metarocq\cite{sozeau2020metacoq}. 
Howeverm overall structure of reasoning holds well even without them. 

The main idea is to separate closed inductive types into modular feature functors and non modular fixpoint operation. 
Following this idea nievly will lead to incosistency, so the fixpoint operation is not present explicitly, but inlined each time.

Resulting feature functors allow open-recursion-style per-functor proofs without relaying on a particular structure of overarching type.
Once desired proofs are complete its possible to assemble the type through inlined fixpoint application and proofs by "closing" the recursion over per-fucntor proofs.

The apporach is illustrated with an example at Fig \ref{fig:alacart_example} that roughtly outlines extension of untyped lambda calculus with with booleans and if-then-else constructions. 
However, there is much more to it that is possible to cover here.

\begin{figure}
\begin{lstlisting}[language=Coq]
(* Exp.v *)
Inductive Exp := 
(* Exp type can be seen as inlined fixpoint 
   of coproduct of feature functors exp_ite and exp_lam *)
  | inj_ite : exp_ite Exp -> Exp
  | inj_lam : exp_lam Exp -> Exp.
Fixpoint thrm : forall (e : Exp) -> ...
intros. destruct e.
(* close recursion *)
  - apply (thrm_ite Exp thrm ...).
  - apply (thrm_lam Exp thrm ...).
Defined.
(* ITE.v *)
Section exp_ite.
Exp : Type.
Inductive exp_ite := 
  | ite : Exp -> Exp -> Exp
  | boolt_lit : bool -> Exp.
(* assume overarching property *)
Variable thrm : forall (e : Exp) -> ... .
(* Prove corresponding per-functor property *)
Definition thrm_ite : forall (e : exp_lam) -> ... .
End exp_ite.
(* Lambda.v *)
(* Ommited for brievity, but analogous to ite.v *)
\end{lstlisting}
  \caption{Minimal example of language extension with ITE constructions.}
  \label{fig:alacart_example}
\end{figure}

It is noticable even in this very simple example that there is some boilerplate code that is tedeous to write by hand. 
So, naturally it is tempting to automate its generation. 

Coq-Elpi\cite{tassi2025elpi} is a rule-based meta-lanauge for Rocq\cite{the_coq_development_team_2024_14542673} that gives a programmer an ability to generate tactics, inductive types and manipulate syntax with binders. 
We chose it over Metarocq for it's debugging infrostructure, binder handling and availability of onboarding material.

\section{Targets for formalization}

There is a significant progress in applying modular techniquies to existing programming languages(e.g. CompCert and CakeML\cite{ebresafe2025certified}), however ...??

\todo[inline]{Turns out there are recent developments in applying modular approaches. That could have been akward.. }

There are several\cite{guha2010essence}\cite{bodin2014trusted} developments that attempt to formalize and reason about JavaScript, however non of them is easy to extend with new features.
Being one of the most used language, JavaScript provides a fertile ground for evaluating existing approaches for modular reasoning. 
Lack of sophisticated type system streamlines the encoding and makes it easier to gradually prove language properties, while keeping the formalization open to extension.
ECMA\cite{ECMA}, an extensive specification in natural language, is also a very welcome addition.

Moreover, JavaScript has several frameworks\cite{React} and dialects(e.g. TypeScript) that enable different styles of programming. 
Ability to reuse proofs about core language for dialects would be a nice showcase of modularity. 
The t39 proposal process\cite{t39} is transparent and well documented thus permitting mechanization of ongoing specification of nightly features before they are adopted into core language.

\todo[inline]{There exists industrial cases where it is paramount to have reusable proofs. For example: React vs Signals proposal.}

To the best of our knowledge no modular proof technique from above was successfully used for mechanisation of a mainstream programming language.

We plan to, at first, follow $\lambda_{\texttt{JS}}$\cite{guha2010essence} formalization and then gradually extend it with features described in ECMA, while preserving the following theorems.

\begin{lstlisting}[numbers=none, language=Coq]
Theorem progress : forall c e, lc e -> 
         isValue e \/ 
         isError e \/ 
         (exists c' e', step c e c' e').

Theorem preservation : forall c e c' e', lc e
                                      -> step c e c' e'
                                      -> lc e'.
\end{lstlisting}

The aim of the project is niether to formalize the whole existing JavaScript semantics nor to develop a generic modular framework. 
Rather the aim is to test how far one can go with mechanisation by specialising existing approach to JavaScript, while maintaining extendability. 
With this goal in mind the following features of JavaScript are of the most interest: mutability, exceptions, reactivity and asynchronicy. 
Ongoing Rocq development is available here\footnote{https://github.com/FrogOfJuly/js-a-la-Carte}.

% \todo[inline]{One can do the same formalization as $\lambda_{\texttt{JS}}$ for Featherweight Java\cite{igarashi2001featherweight}. }

\section{Discussion}

There are other solutions to increase modularity of proofs. 

\medskip

\textbf{Extensible metatheory mechanization via family polymorphism. } FPOP\cite{jin2023extensible} and Rocqet\cite{ebresafe2025certified} are a Rocq language extensions which compile modular inductive types into Rocq modules allowing extension with the help of 
OO-inspired family polymorphism with late bindings. 

Despite its success in formalizing CompCert and CakeML its modular type representation as modules is virtually incompatible with the rest of Rocq which increases learning curve and locks development to this particular dialect. 
\todo[inline]{Am I misinterpreting all of this and it's OK and actually the best solution?}

\medskip
\textbf{Program Logics à la Carte}\cite{vistrup2025program} achieves modularity by encoding effect-emitting(e.g. non-termination, exception, concurrency, etc.) components of the language as fragments of program logic. 
Language semantics is expressed as interaction trees\cite{xia2019interaction}: coinductively defined datatype for representing effectful computations. 
Development provides several program logics fragment which correspond to commonly encountered pieces in different programming languages. 

From the practical point of view however, this approach introduces prohibitive degree of indirection to encoding and proofs, especially if it is required to define new program logic fragments.

\todo[inline]{Does it?}


\medskip
\textbf{Intrinsically-typed definitional interpreters {\`a} la carte}\cite{van2022intrinsically} leverages finatary containers\cite{altenkirch2015indexed} and algebras over them to introduce "intrinsically-typed language fragments".
Those bring together common syntax and semantics of chosen language features, while allowing composition. 

While very satisfying on it's own this approach also suffers from indirectness of modular type encoding. Learning curve for container machinery is quite steep and thus makes it hard to adopt this way of doing proofs for larger languages.



\todo[inline]{Should be worded better.}

\medskip

% \todo[inline]{It's interesting to look into the possibility of gradually encoding calculus of inductive constructions in a modular fashion.}

Proof modularity comes with the cost of departing from the usual way of reasoning about inductive types. 
Even if in case of Coq à la Carte the departure is not quite dramatic, it still requires to rethink how one approaches proofs.

The ideal solution would be to have a correspondence between proofs for modular representation and equivalent inductive types. 
There is an existing work\cite{cohen2024trocq} that could enable such transfer of proofs. 

\todo[inline]{Talk about how they achieve that and is it possible to leverage that for functor representation of chosen datatype.}

% \todo[inline]{Is it possible to use containers as a meta language, while presreving ability to do actual reasoning with inductive types in Rocq?}


\bibliographystyle{ACM-Reference-Format}
\bibliography{lib}

\appendix


\end{document}
