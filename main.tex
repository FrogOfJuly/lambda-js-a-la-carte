%%
%% This is file `sample-manuscript.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,manuscript')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-manuscript.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[sigplan,nonacm,review]{acmart}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2025}
\acmYear{2026}
\acmDOI{XXXXXXX.XXXXXXX}
%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[Conference acronym 'XX]{Make sure to enter the correct
  conference title from your rights confirmation email}{June 03--05,
  2018}{Woodstock, NY}
%%
%%  Uncomment \acmBooktitle if the title of the proceedings is different
%%  from ``Proceedings of ...''!
%%
%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%  June 03--05, 2018, Woodstock, NY}
\acmISBN{978-1-4503-XXXX-X/2018/06}
%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
% \citestyle{acmauthoryear}

\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\newcommand\code[1]{{\tt\small #1}}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{ltblue}{rgb}{0,0.4,0.4}
\definecolor{dkviolet}{rgb}{0.3,0,0.5}
\definecolor{dkblue}{rgb}{0.3,0,0.5}
\definecolor{dkred}{rgb}{0.5,0,0.3}

\lstdefinestyle{mystyle}{
    % backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

% lstlisting coq style (inspired from a file of Assia Mahboubi)
\lstdefinelanguage{Coq}{ 
    % Anything betweeen $ becomes LaTeX math mode
    mathescape=true,
    % Comments may or not include Latex commands
    texcl=false, 
    % Vernacular commands
    morekeywords=[1]{Section, Module, End, Require, Import, Export,
        Variable, Variables, Parameter, Parameters, Axiom, Hypothesis,
        Hypotheses, Notation, Local, Tactic, Reserved, Scope, Open, Close,
        Bind, Delimit, Definition, Let, Ltac, Fixpoint, CoFixpoint, Add,
        Morphism, Relation, Implicit, Arguments, Unset, Contextual,
        Strict, Prenex, Implicits, Inductive, CoInductive, Record,
        Structure, Canonical, Coercion, Context, Class, Global, Instance,
        Program, Infix, Theorem, Lemma, Corollary, Proposition, Fact,
        Remark, Example, Proof, Goal, Save, Qed, Defined, Hint, Resolve,
        Rewrite, View, Search, Show, Print, Printing, All, Eval, Check,
        Projections, inside, outside, Def},
    % Gallina
    morekeywords=[2]{forall, exists, exists2, fun, fix, cofix, struct,
        match, with, end, as, in, return, let, if, is, then, else, for, of,
        nosimpl, when, eqn},
    % Sorts
    morekeywords=[3]{Type, Prop, Set, true, false, option},
    % Various tactics, some are std Coq subsumed by ssr, for the manual purpose
    morekeywords=[4]{pose, set, move, case, elim, apply, clear, hnf,
        intro, intros, generalize, rename, pattern, after, destruct,
        induction, using, refine, inversion, injection, rewrite, congr,
        unlock, compute, ring, field, fourier, replace, fold, unfold,
        change, cutrewrite, simpl, have, suff, wlog, suffices, without,
        loss, nat_norm, assert, remember, cut, trivial, revert, bool_congr, nat_congr,
        symmetry, transitivity, auto, split, left, right, autorewrite},
    % Terminators
    morekeywords=[5]{by, done, exact, reflexivity, tauto, romega, omega,
        assumption, solve, contradiction, discriminate},
    % Control
    morekeywords=[6]{do, last, first, try, idtac, repeat},
    % Comments delimiters, we do turn this off for the manual
    morecomment=[s]{(*}{*)},
    % Spaces are not displayed as a special character
    showstringspaces=false,
    % String delimiters
    morestring=[b]",
    morestring=[d]’,
    % Size of tabulations
    tabsize=3,
    % Enables ASCII chars 128 to 255
    extendedchars=false,
    % Case sensitivity
    sensitive=true,
    % Automatic breaking of long lines
    breaklines=false,
    % Default style fors listings
    basicstyle=\small,
    % Position of captions is bottom
    captionpos=b,
    % flexible columns
    columns=[l]flexible,
    % Style for (listings') identifiers
    identifierstyle={\ttfamily\color{black}},
    % Style for declaration keywords
    keywordstyle=[1]{\ttfamily\color{dkviolet}},
    % Style for gallina keywords
    keywordstyle=[2]{\ttfamily\color{blue}},
    % Style for sorts keywords
    keywordstyle=[3]{\ttfamily\color{ltblue}},
    % Style for tactics keywords
    keywordstyle=[4]{\ttfamily\color{dkviolet}},
    % Style for terminators keywords
    keywordstyle=[5]{\ttfamily\color{dkred}},
    %Style for iterators
    %keywordstyle=[6]{\ttfamily\color{dkpink}},
    % Style for strings
    stringstyle=\ttfamily,
    % Style for comments
    commentstyle={\ttfamily\color{dkgreen}},
    %moredelim=**[is][\ttfamily\color{red}]{/&}{&/},
    literate=
    {\\forall}{{\color{dkgreen}{$\forall\;$}}}1
    {\\exists}{{$\exists\;$}}1
    {<-}{{$\leftarrow\;$}}1
    {=>}{{$\Rightarrow\;$}}1
    {==}{{\code{==}\;}}1
    {==>}{{\code{==>}\;}}1
    %    {:>}{{\code{:>}\;}}1
    {->}{{$\rightarrow\;$}}1
    {<->}{{$\leftrightarrow\;$}}1
    {<==}{{$\leq\;$}}1
    {\#}{{$^\star$}}1 
    {\\o}{{$\circ\;$}}1 
    {\@}{{$\cdot$}}1 
    {\/\\}{{$\wedge\;$}}1
    {\\\/}{{$\vee\;$}}1
    {++}{{\code{++}}}1
    {~}{{$\sim$}}1
    {\@\@}{{$@$}}1
    {\\mapsto}{{$\mapsto\;$}}1
    {\\hline}{{\rule{\linewidth}{0.5pt}}}1
    %
}[keywords,comments,strings]

\lstset{style=mystyle}

\usepackage{todonotes}
\setlength {\marginparwidth }{2cm}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{$\lambda_{\texttt{JS}}$ à la Carte}
%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.

\author{Kirill Golubev}
\email{kirill.golubev@utu.fi}
\orcid{0009-0002-2709-5241}
\affiliation{%
  \institution{University of Turku}
  \city{Turku}
  \country{Finland}
}

\author{Mikhail Barash}
\email{mikhail.barash@uib.no}
\orcid{0000-0002-7067-2588}
\affiliation{%
  \institution{University of Bergen}
  \city{Bergen}
  \country{Norway}
}
% \authornote{
%   Secondary supervisor.
% }

\author{Jaakko Järvi}
\email{jaakko.jarvi@utu.fi}
\orcid{0000-0002-3418-7366}
\affiliation{%
  \institution{University of Turku}
  \city{Turku}
  \country{Finland}
}

% \authornote{
%   Primary supervisor.
% }



% \authornote{
%   Primary supervisor: Jaakko Järvi, jaakko.jarvi@utu.fi, University of Turku, Turku, Finland, orcid: 0000-0002-3418-7366\\
%   Secondary supervisor: Mikhail Barash, mikhail.barash@uib.no, University of Bergen, Bergen, Norway, orcid: 0000-0002-7067-2588
% }


%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Golubev}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
 <concept>
<concept_id>10011007.10010940.10010992.10010998.10010999</concept_id>
<concept_desc>Software and its engineering~Software verification</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~Software verification}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Formal methods, modular proofs, JavaScript.}

% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

\maketitle

\section{Introduction}

A programming language formalization gives a single source of truth
about the language behavior.
Unless mechanized,
a formalization can be erroneous and logically unsound.
Mechanizing a formalization can guarantee that
the semantics of the language is sound,
and that
the formalization is free of bugs.
For a complex language, however,
mechanization is laborious,
as is maintaining an existing mechanization as the language evolves. Mechanizations are usually monolithic
such that each new feature requires manually rewriting existing code.
At its core this is due to the manifestation of the expression problem for inductive types. 
% This issue stems from the extensibility limitations of inductive types that are used to model language semantics, with the expression problem at the core. 

Several solutions~\cite{jin2023extensible, vistrup2025program, van2022intrinsically, forster2020coq} have been proposed to improve proof reuse in mechanizations, and some~\cite{ebresafe2025certified} have found use in practice (cf.~CompCert~\cite{leroy2016compcert} and CakeML~\cite{kumar2014cakeml}). Our work targets JavaScript semantics with one these approaches, specializing \emph{Coq à la Carte}~\cite{forster2020coq}. We aim to show that it is possible to reason about modern heavily used languages in an modular fashion keeping mechanization open to extension with new features. 


% We are especially interested in mechanizing \emph{reactivity} in JavaScript,
% which is popularized by various developer frameworks
% such as React~\cite{React}, Solid~\cite{Solid}, and others.

\section{Background}

\emph{Datatypes à la Carte}~\cite{swierstra2008data}
popularizes the idea of
\emph{extensible} inductive datatypes. 
One effort to bring this idea to proof assistants
was \emph{Coq à la Carte}~\cite{forster2020coq},
which enables modularity in Rocq~\cite{the_coq_development_team_2024_14542673} proofs.
However,
directly using tools developed there
is prohibitively difficult
due to their dependency on an outdated version of Metarocq~\cite{sozeau2020metacoq}.

The key insight to extensibility is that it is possible to represent an inductive type as a fixed point of a particular functor. Unfortunately, attempting such a decomposition na\"ively leads to inconsistency\footnote{\texttt{Fix ($\Lambda$ A. A -> False)} allows to obtain proof of \texttt{False}. See appendix Figure \ref{appendix:false_proof}}. 
Therefore, it is not possible to use explicit fixed-point operations for inductive type decomposition in theorem provers.
As shown in the Coq à la Carte approach,
this issue can be avoided by \emph{inlining} fixed-point operations.  
Resulting functors will then allow open-recursion-style per-functor proofs,
which will not rely on a particular structure of the decomposed type.
Once the desired proofs are complete,
the type can be assembled from the corresponding feature functors as a fixed point of their coproduct,
and proofs can be assembled from
per-functor proofs,
by ``closing'' recursion over them. These ideas are outlined in Figure~\ref{fig:alacart_example}.

\begin{figure}
\begin{lstlisting}[language=Coq]
(* Exp.v *)
Inductive Exp := 
(* Exp type can be seen as an inlined fixed point 
   of coproduct of feature functors exp_ite and exp_lam *)
  | inj_ite : exp_ite Exp -> Exp
  | inj_lam : exp_lam Exp -> Exp.
Fixpoint thrm : forall (e : Exp) -> ...
intros. destruct e.
(* close recursion *)
  - apply (thrm_ite Exp thrm ...).
  - apply (thrm_lam Exp thrm ...).
Defined.
(* ITE.v *)
Section exp_ite.
Exp : Type.
Inductive exp_ite := 
  | ite : Exp -> Exp -> Exp
  | boolt_lit : bool -> Exp.
(* assume overarching property *)
Variable thrm : forall (e : Exp) -> ... .
(* Prove corresponding per-functor property *)
Definition thrm_ite : forall (e : exp_lam) -> ... .
End exp_ite.
(* Lambda.v: omitted, similar to ITE.v *)
\end{lstlisting}
  \caption{Minimal example of language extension with ITE constructions. There is much more to it, for details, please refer to our development.}
  \label{fig:alacart_example}
\end{figure}

There is another 


%The approach is illustrated with an example at Fig \ref{fig:alacart_example} 
%that roughly outlines extension of untyped lambda calculus with booleans 
%and if-then-else constructions. 
%However, there is much more to it than is possible to cover here.
As can be seen in the code example,
there is a considerable amount of boilerplate,
and it can be automatically generated.
Here we mention Coq-Elpi~\cite{tassi2025elpi}, which is a rule-based metalanguage for Rocq;
it gives a programmer the ability to generate tactics,
inductive types and manipulate Rocq terms.

\section{Targets for Mechanization}

% In our work,
% we attempt an extensible mechanization of the JavaScript semantics\footnote{We note that mechanizing the entirety of the JavaScript semantics
% and developing a generic modular framework are non-goals.}
% by \emph{specializing} the à la carte approach described above.
% This specialization will be focused on developing meta-tools that target an impure imperative language without concurrency (in our case, JavaScript),
% rather than developing a generic framework suitable for a wide range of target languages.

None of the existing modular approaches targets JavaScript semantics.
We observe that extending existing JavaScript mechanizations
(cf., e.g.,~\cite{guha2010essence,bodin2014trusted}, which are based on various editions of the exhaustive natural language specification ECMA-262~\cite{ECMA})
with support for new features
is impossible without manually rewriting a significant portion of an existing codebase.

% Maybe this and next paragraphs should go to the introduction?

Being one of the most-used languages, JavaScript provides a fertile ground for evaluating approaches for modular reasoning.
Lack of a type system streamlines the encoding, while the ability to reuse proofs makes it practical to mechanize dialects (e.g. JSX, TypeScript), reason about various frameworks(e.g. React~\cite{React}, Solid~\cite{Solid}, etc) and verify feature specifications while they are still in development. 

% Being extensible, proofs about the core language
% will be reusable to mechanize the most recent additions to the language
% (i.e., the upcoming features -- even before they become part of the ECMA-262 specification).
% It will also be possible to reuse proofs for further properties
% of the language's dialects (e.g., JavaScript XML, TypeScript),
% as well as various JavaScript frameworks.

% \textcolor{red}{(e.g., React, Solid, Angular, Vue, etc)}.

We plan to follow the $\lambda_{\texttt{JS}}$ formalization~\cite{guha2010essence},
and then extend it with the relevant features one-by-one,
while maintaining the following safety theorems:

\begin{lstlisting}[numbers=none, language=Coq]
Theorem progress : forall c e, lc e -> 
         isValue e \/ 
         isError e \/ 
         (exists c' e', step c e c' e').

Theorem preservation : forall c e c' e', lc e
                                      -> step c e c' e'
                                      -> lc e'.
\end{lstlisting}

We are particularly interested in mechanizing
mutability, exceptions, asynchrony, and reactivity of JavaScript, and we seek to establish soundness of the TC39 \emph{Signals} proposal~\cite{signals-proposal-t39} that unifies reactive primitives across various developer frameworks. 



Our ongoing Rocq mechanization is available on
GitHub\footnote{\url{https://github.com/FrogOfJuly/js-a-la-Carte}}. 
The development includes feature functors for: call-by-value untyped lambda calculus core, mutability with ML-style references, \texttt{if}-\texttt{then}-\texttt{else} constructions, as well as simple error handling that interacts with ITE, mutability and the core.

To the best of our knowledge, feature functor interactions have not been previously investigated, and it is interesting to see how they will shape our mechanization.

\section{Related work}

There are other solutions that address the extensibility of proofs. 

% \medskip

\paragraph{Extensible metatheory mechanization via family polymorphism} FPOP~\cite{jin2023extensible} and Rocqet~\cite{ebresafe2025certified} are Rocq language extensions that compile inductive types into Rocq modules, allowing extensibility with the help of OO-inspired family polymorphism with late bindings. 
%
%
%
%
Despite its success in formalizing CompCert and CakeML, its extensible inductive type representation as Rocq modules is virtually incompatible with usual inductive types, which worsens the learning curve and locks development to this particular dialect. 
% \todo[inline]{Am I misinterpreting all of this, and it's OK and actually the best solution?}

% \medskip
\paragraph{Program Logics à la Carte}
Vistrup et al.~\cite{vistrup2025program} achieve extensibility by encoding effect-emitting
(e.g., non-termination, exception, concurrency, etc.)
components of the language as fragments of program logic. 
Language semantics is expressed as interaction trees~\cite{xia2019interaction}: a coinductively defined datatype for representing effectful computations. 
Development provides several program logic fragments that correspond to commonly encountered pieces in different programming languages. 
%
%
%
%
From the practical point of view, however, this approach introduces considerable indirection to language encoding and proofs, especially if it is required to define new program logic fragments.

% \medskip
\paragraph{Intrinsically-typed definitional interpreters {\`a} la carte}
Van der Rest et al.~\cite{van2022intrinsically} leverage finitary containers~\cite{altenkirch2015indexed} and algebras over them to introduce "intrinsically-typed language fragments".
Those bring together common syntax and semantics of chosen language features, while allowing composition. 
%
%
%
%
While very satisfying on its own, this approach also suffers from the indirectness of type encoding. Learning curve for container machinery is quite steep, which makes it difficult to adopt the approach to larger languages.

% \medskip

\section{Discussion}

Proof modularity comes with the cost of departing from the usual way of reasoning about inductive types. 
In the case of Coq à la Carte, the departure is not quite dramatic, but it still requires to rethink how one approaches proofs.

The ideal solution would be to have a correspondence between proofs for modular representation and equivalent inductive types. Trocq~\cite{cohen2024trocq} enables such transfer. Modular encoding of the language is isomorphic to its monolithic counterpart, so there should be no obstacles to exposing a more familiar interface for those uses that do not benefit from extensibility.


\bibliographystyle{ACM-Reference-Format}
\bibliography{lib}

\appendix

\section{Additional figures}

\begin{figure}[H]
\begin{lstlisting}[language=Coq]
(* Rocq won't allow direct definition
   as showed in Data types a la carte:
   data Fix f = In (f (Fix f))
   so we mimic it with axioms.
*)
Axiom Fix : (Type -> Type) -> Type.
Axiom fix_def : forall {f : Type -> Type}, Fix f = f (Fix f).

Theorem fix_implies_false : False. 
Proof.
    remember (Fix (fun A => A -> False)) as A eqn:HeqA.
    assert (not_a : A -> False). { 
        intros X. assert (X' :=  X).
        rewrite HeqA in X.
        rewrite fix_def in X.
        rewrite <- HeqA in X.
        exact (X X').
    }
    apply not_a.
    rewrite HeqA.
    rewrite fix_def.
    rewrite <- HeqA.
    exact not_a.
Qed.
\end{lstlisting}
\caption{\texttt{Fix} is inconsistent}
  \label{appendix:false_proof}
\end{figure}

\end{document}
